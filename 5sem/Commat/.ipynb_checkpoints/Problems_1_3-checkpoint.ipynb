{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeXTSdSfKdL2"
   },
   "source": [
    "## *Задача 1.  Генератор матриц* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19smb2owQS40"
   },
   "source": [
    "Реализовать генератор матрциц, который должен поддерживать функции(без использования циклов):\n",
    "* Генерация абсолютно случайной матрицы $n\\times m$\n",
    "* Генерация случайной диагональной матрицы $n\\times n$\n",
    "* Генерация случайной верхнетреугольной матрицы\n",
    "* Генерация случайной нижнетреугольной матрицы\n",
    "* Генерация симметричной матрицы\n",
    "* Генерация вырожденной матрицы\n",
    "* Генерация матрицы ступенчатого вида $n\\times n$ ранга $m$\n",
    "* Генерация возмущения матрицы $n\\times m$, каждый элемент которой не превосходит по модулю заданный $\\varepsilon$\n",
    "\n",
    "Оценить вероятность того, что созданная матрица будет вырожденной. \n",
    "\n",
    "Оценить величину нормы матрицы возмущений в зависимости от параметра $\\varepsilon$ (оценить верхную границу).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Абсолютно случайная матрица n*m\n",
      "[[0.38158624 0.58489283 0.88587399]\n",
      " [0.79039847 0.22110717 0.64952198]\n",
      " [0.27319145 0.85306971 0.97500632]\n",
      " [0.78260711 0.55309886 0.97079853]\n",
      " [0.6901646  0.91505883 0.16673274]]\n",
      "Диагональная случайная матрица n*n\n",
      "[[0.42330078 0.         0.         0.         0.        ]\n",
      " [0.         0.64061765 0.         0.         0.        ]\n",
      " [0.         0.         0.30246038 0.         0.        ]\n",
      " [0.         0.         0.         0.90882521 0.        ]\n",
      " [0.         0.         0.         0.         0.19092327]]\n",
      "Случайная верхнетреугольная матрица\n",
      "[[0.57342579 0.23276761 0.97299342 0.84466716 0.51239666]\n",
      " [0.         0.23276761 0.97299342 0.84466716 0.51239666]\n",
      " [0.         0.         0.97299342 0.84466716 0.51239666]\n",
      " [0.         0.         0.         0.84466716 0.51239666]\n",
      " [0.         0.         0.         0.         0.51239666]]\n",
      "Случайная нижнетреугольная матрица\n",
      "[[0.25653616 0.         0.         0.         0.        ]\n",
      " [0.25653616 0.27725817 0.         0.         0.        ]\n",
      " [0.25653616 0.27725817 0.37075814 0.         0.        ]\n",
      " [0.25653616 0.27725817 0.37075814 0.6858537  0.        ]\n",
      " [0.25653616 0.27725817 0.37075814 0.6858537  0.63222185]]\n",
      "Симметричная матрица\n",
      "[[0.01382109 0.61596338 0.61548032 0.67309637 0.15751674]\n",
      " [0.61596338 0.63506601 0.86850237 0.93130181 0.5570091 ]\n",
      " [0.61548032 0.86850237 1.87064153 0.83689308 0.38915407]\n",
      " [0.67309637 0.93130181 0.83689308 1.80829227 0.56769443]\n",
      " [0.15751674 0.5570091  0.38915407 0.56769443 1.08838369]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "n = 5\n",
    "m = 3\n",
    "print(\"Абсолютно случайная матрица n*m\")\n",
    "print(np.random.random((n, m)))\n",
    "print(\"Диагональная случайная матрица n*n\")\n",
    "print(np.diag(np.random.random((n))))\n",
    "print(\"Случайная верхнетреугольная матрица\")\n",
    "print(np.triu(np.random.random((n)), k = 0))\n",
    "print(\"Случайная нижнетреугольная матрица\")\n",
    "print(np.tril(np.random.random((n)), k = 0))\n",
    "print(\"Симметричная матрица\")\n",
    "a = np.random.rand(n, n)\n",
    "print(np.tril(a) + np.tril(a).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS3EHa1aKmJi"
   },
   "source": [
    "# Задача 2. Эквивалентность первых двух норм.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMUUtmljQZO1"
   },
   "source": [
    "Найдите константы $C_1$  и  $C_2$ такие, что\n",
    "\n",
    "$\\ C_1||\\mathbf{x}||_2\\leq||\\mathbf{x}||_1\\leq C_2||\\mathbf{x}||_2$ \n",
    "\n",
    "\n",
    "Указание: в качестве подсказки можно использовать визуализацию норм из документа с теорией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpR6GBRtKmXq"
   },
   "source": [
    "# Задача 3.  Евклидова и бесконечная норма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ7BfspuTsOt"
   },
   "source": [
    " Пусть x — вектор размерности m, а A — матрица m×n. Докажите следующие неравенства и приведите\n",
    "примеры таких x и A, при которых неравенства обращаются в равенства: \n",
    "\n",
    "- $\\|x\\|_2 \\leq \\sqrt{m}\\|x\\|_{\\infty}$\n",
    "- $\\|A\\|_{\\infty} \\leq \\sqrt{n}\\|A\\|_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-476ZEtKmk5"
   },
   "source": [
    "# Задача 4. Норма Фробениуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzG3RPf-T07c"
   },
   "source": [
    "Докажите, что для любой унитарной матрицы U (и для произвольной матрицы A) имеет место равенство\n",
    "\n",
    " $∥UA∥_F = ∥AU∥_F = ∥A∥_F$ , \n",
    " \n",
    " где $∥ ∥_F$ — норма Фробениуса.\n",
    "\n",
    "Указание.  \n",
    "Задачу можно решить без вычислений, если использовать геометрический смысл нормы Фробениуса и геометрические свойства умножения на унитарную матрицу (что при умножении на неё сохраняется). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8jGlqhJKmpB"
   },
   "source": [
    "# Задача 5. Тензорная свёртка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smdRrcYuT4he"
   },
   "source": [
    "Рассмотрим функцию, отображающую шесть тензоров на один тензор: $Z\\left(\\lambda^{(1)}, \\lambda^{(2)}, \\lambda^{(3)}, \\Gamma^{(1)}, \\Gamma^{(2)}, U\\right)$ :\n",
    "\n",
    "\n",
    "$$\n",
    "Z_{a h i j}=\\sum_{b c d e f g} \\lambda^{(1)}{ }_{a b} \\Gamma_{c b d}^{(1)} \\lambda^{(2)}{ }_{d e} \\Gamma_{f e g}^{(2)} \\lambda_{g h}^{(3)} U_{i j c f}\n",
    "$$ \n",
    "\n",
    "редположив, что все индексы пробегают значения от 1 до χ, проведите эксперимент и сравните скорость\n",
    "различных реализаций функции Z. Исследуйте значения χ в диапазоне 3–50. \n",
    "\n",
    "\n",
    "- В файле convolution. ipynb вы можете найти релизацию глупого способа вычисления этой свертки, который требует $\\chi^4 \\times \\chi^6=\\chi^{10}$ операций. На самом деле это можно вычислить гораздо быстрее!\n",
    "- С помощью функции numpy . einsum (нужно использовать аргумент optimize), можно добиться намного большей производительности. Чтобы понять, что происходит под капотом, воспользуйтесь функцией numpy.einsum_path. Какое минимальное количество операций требуется для вычисления $Z$ ?\n",
    "- Посмотрев на вывод функции numpy.einsum_path, peализуйте алгоритм для вычисления $Z$, который столь же эффективен, как numpy.einsum, но использует более элементарные numpy.dot и numpy.tensor_dot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "634QUTkyKnWR"
   },
   "source": [
    "# Задача 6.  k-means clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gHzjikte83x"
   },
   "source": [
    "Выбор метрики (нормы разницы между любыми двумя векторами, или функции расстояния между любой парой точек) очень важен для многих алгоритмов машинного обучения. Рассмотрим на примере задачи кластеризации. \n",
    "\n",
    "Кластеризация — это разделение множества входных векторов на группы (кластеры) по степени «схожести» друг с другом.\n",
    "\n",
    "Кластеризация в Data Mining приобретает ценность тогда, когда она выступает одним из этапов анализа данных, построения законченного аналитического решения. Аналитику часто легче выделить группы схожих объектов, изучить их особенности и построить для каждой группы отдельную модель, чем создавать одну общую модель для всех данных. Таким приемом постоянно пользуются в маркетинге, выделяя группы клиентов, покупателей, товаров и разрабатывая для каждой из них отдельную стратегию.\n",
    "\n",
    "\n",
    "Евклидова метрика \n",
    "\n",
    "\n",
    "— наиболее распространенная. Она является геометрическим расстоянием в многомерном пространстве.\n",
    "\n",
    "\n",
    "Квадрат евклидовой метрики. \n",
    "\n",
    "\n",
    "Иногда может возникнуть желание возвести в квадрат стандартное евклидово расстояние, чтобы придать большие веса более отдаленным друг от друга объектам.\n",
    "\n",
    "\n",
    "Метрика городских кварталов (манхэттенская). \n",
    "\n",
    "\n",
    "Это расстояние является суммой модулей разностей координат. В большинстве случаев эта метрика приводит к таким же результатам, как и для обычного расстояния Евклида. Однако отметим, что для этой меры влияние отдельных больших разностей (выбросов) уменьшается (так как они не возводятся в квадрат).\n",
    "\n",
    "Расстояние Чебышева. \n",
    "\n",
    "Это метрика шахматной доски (Расстоянием Чебышёва между n-мерными числовыми векторами называется максимум модуля разности компонент этих векторов). Это расстояние может оказаться полезным, когда желают определить два объекта как «различные», если они различаются по какой-либо одной координате (каким-либо одним измерением).\n",
    "\n",
    "Расстояние Чебышёва называют также метрикой Чебышёва, равномерной метрикой, sup-метрикой и бокс-метрикой; также иногда она называется метрикой решётки, метрикой шахматной доски, метрикой хода короля и 8-метрикой.\n",
    "\n",
    "Степенная метрика. \n",
    "\n",
    "Иногда желают прогрессивно увеличить или уменьшить вес, относящийся к размерности, для которой соответствующие объекты сильно отличаются. Это может быть достигнуто с использованием степенного расстояния.\n",
    "\n",
    "\n",
    "Выбор метрики (критерия схожести) лежит полностью на исследователе. При выборе различных мер результаты кластеризации могут существенно отличаться.\n",
    "\n",
    "Алгоритм k-means (k-средних)\n",
    "\n",
    "Наиболее простой, но в то же время достаточно неточный метод кластеризации в классической реализации. Он разбивает множество элементов векторного пространства на заранее известное число кластеров k. Действие алгоритма таково, что он стремится минимизировать среднеквадратичное отклонение на точках каждого кластера. Основная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Алгоритм завершается, когда на какой-то итерации не происходит изменения кластеров.\n",
    "\n",
    "Проблемы алгоритма k-means:\n",
    "* необходимо заранее знать количество кластеров. Мной было предложено метод определения количества кластеров, который основывался на нахождении кластеров, распределенных по некоему закону (в моем случае все сводилось к нормальному закону). После этого выполнялся классический алгоритм k-means, который давал более точные результаты.\n",
    "* алгоритм очень чувствителен к выбору начальных центров кластеров. Классический вариант подразумевает случайный выбор класторов, что очень часто являлось источником погрешности. Как вариант решения, необходимо проводить исследования объекта для более точного определения центров начальных кластеров. В моем случае на начальном этапе предлагается принимать в качестве центов самые отдаленные точки кластеров.\n",
    "* не справляется с задачей, когда объект принадлежит к разным кластерам в равной степени или не принадлежит ни одному.\n",
    "\n",
    "\n",
    "В блокноте kmeans.ipynb вы можете найти наивную реализацию.\n",
    "Изучите код, убедитесь, что вы его поняли. Вы найдете там две функции dist_i и dist_ij, которые\n",
    "(намеренно) реализованы довольно неэффективно. Улучшите их, избавившись от циклов с помощью век-\n",
    "торизации из numpy, и измерьте ускорение алгоритма в целом при N = 10000.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKnAIng1T-Ex"
   },
   "source": [
    "# Дополнительное задание. Нечеткий алгоритм кластеризации с-means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umU-jwFAT7nj"
   },
   "source": [
    "С последней проблемой k-means успешно справляется алгоритм с-means. Вместо однозначного ответа на вопрос к какому кластеру относится объект, он определяет вероятность того, что объект принадлежит к тому или иному кластеру. Таким образом, утверждение «объект А принадлежит к кластеру 1 с вероятностью 90%, к кластеру 2 — 10% » верно и более удобно.\n",
    "\n",
    "Остальные проблемы у с-means такие же, как у k-means, но они нивелируются благодаря нечеткости разбиения.\n",
    "\n",
    "Метод нечеткой кластеризации C-средних имеет ограниченное применение из-за существенного недостатка — невозможность корректного разбиения на кластеры, в случае когда кластеры имеют различную дисперсию по различным размерностям (осям) элементов (например, кластер имеет форму эллипса). Данный недостаток устранен в алгоритмах Mixture models и GMM (Gaussian mixture models). \n",
    "\n",
    "\n",
    "Документация методов кластеризации для sklearn есть здесь https://scikit-learn.org/stable/modules/clustering.html#k-means . \n",
    "\n",
    "\n",
    "\n",
    "Используя библиотеку scikit-learn, реализуйте Gaussian mixture models и обычный k-means.  Подберите такой набор данных, на котором первый метод справляется хорошо, а второй метод даёт плохие результаты, и продемонстрируйте это. Сделайте это для нескольких разных метрик и сравните результаты между собой.\n",
    "\n",
    "https://scikit-learn.ru/example/  примеры подобного.\n",
    "\n",
    "https://neurohive.io/ru/osnovy-data-science/vvedenie-v-scikit-learn/  введение в sklearn. На этом сайте много полезных статей и ссылок на курсы. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MeXTSdSfKdL2",
    "sS3EHa1aKmJi",
    "gpR6GBRtKmXq",
    "8-476ZEtKmk5",
    "s8jGlqhJKmpB",
    "634QUTkyKnWR",
    "gKnAIng1T-Ex"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
