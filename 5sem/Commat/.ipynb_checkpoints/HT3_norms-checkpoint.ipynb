{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeXTSdSfKdL2"
   },
   "source": [
    "## *Задача 1.  Генератор матриц* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19smb2owQS40"
   },
   "source": [
    "Реализовать генератор матрциц, который должен поддерживать функции(без использования циклов):\n",
    "* Генерация абсолютно случайной матрицы $n\\times m$\n",
    "* Генерация случайной диагональной матрицы $n\\times n$\n",
    "* Генерация случайной верхнетреугольной матрицы\n",
    "* Генерация случайной нижнетреугольной матрицы\n",
    "* Генерация симметричной матрицы\n",
    "* Генерация вырожденной матрицы\n",
    "* Генерация матрицы ступенчатого вида $n\\times n$ ранга $m$\n",
    "* Генерация возмущения матрицы $n\\times m$, каждый элемент которой не превосходит по модулю заданный $\\varepsilon$\n",
    "\n",
    "Оценить вероятность того, что созданная матрица будет вырожденной. \n",
    "\n",
    "Оценить величину нормы матрицы возмущений в зависимости от параметра $\\varepsilon$ (оценить верхную границу).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ступенчатая матрица n*n ранга m\n",
      "[[0.35396905 0.30171209 0.49520377 0.52449713 0.70466422 0.63629084]\n",
      " [0.         0.31966592 0.7359286  0.18839553 0.94018087 0.53565421]\n",
      " [0.         0.         0.71946747 0.70093811 0.47605516 0.74309549]\n",
      " [0.         0.         0.         0.11681986 0.93588167 0.88953687]\n",
      " [0.         0.         0.         0.         0.0396696  0.16075123]\n",
      " [0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "n = 5\n",
    "m = 3\n",
    "'''\n",
    "print(\"Абсолютно случайная матрица n*m\")\n",
    "print(np.random.random((n, m)))\n",
    "print(\"Диагональная случайная матрица n*n\")\n",
    "a = np.zeros((n, n), float)\n",
    "np.fill_diagonal(a, np.random.rand(n))\n",
    "print(a)\n",
    "print(\"Случайная верхнетреугольная матрица\")\n",
    "print(np.triu(np.random.random((n)), k = 0))\n",
    "print(\"Случайная нижнетреугольная матрица\")\n",
    "print(np.tril(np.random.random((n)), k = 0))\n",
    "print(\"Симметричная матрица\")\n",
    "a = np.random.rand(n, n)\n",
    "a = np.tril(a) + np.tril(a).T\n",
    "print(a)\n",
    "\n",
    "print(\"Вырожденная матрица\")\n",
    "a = np.random.rand(n, n)\n",
    "print(a)\n",
    "print(np.linalg.det(a))\n",
    "'''\n",
    "n = 6\n",
    "m = 5\n",
    "print(\"Ступенчатая матрица n*n ранга m\")\n",
    "a = np.random.random((n, n))\n",
    "sh1 = np.triu(np.ones((m, m)))\n",
    "sh2 = np.ones((m, n - m))\n",
    "sh3 = np.zeros((n - m, n))\n",
    "shape = np.vstack((np.hstack((sh1, sh2)), sh3))\n",
    "a = a * shape\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS3EHa1aKmJi"
   },
   "source": [
    "# Задача 2. Эквивалентность первых двух норм.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMUUtmljQZO1"
   },
   "source": [
    "Найдите константы $C_1$  и  $C_2$ такие, что\n",
    "\n",
    "$\\ C_1||\\mathbf{x}||_2\\leq||\\mathbf{x}||_1\\leq C_2||\\mathbf{x}||_2$ \n",
    "\n",
    "\n",
    "Указание: в качестве подсказки можно использовать визуализацию норм из документа с теорией. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 = 1.1544488167295877\n",
      "C2 = 2.2356873882065296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nC1 = 1.1026288780635476\\nC2 = 2.235176645875752\\n\\nC1 = 1.1173408176507174\\nC2 = 2.235903466061794\\n\\nC1 = 1.1136659273429736\\nC2 = 2.2360269616766137\\n\\nC1 = 1.091236262999598\\nC2 = 2.2356429121918144\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "n = 5\n",
    "C1 = 10000\n",
    "C2 = 0\n",
    "for i in range(100000):\n",
    "    x = np.random.random(n) * random.randrange(-1000, 1000)\n",
    "    #print(x)\n",
    "    l1 = np.linalg.norm(x, 1)\n",
    "    l2 = np.linalg.norm(x, 2)\n",
    "    #print(\"||x||L1 =\", l1, end = ' ')\n",
    "    #print(\"||x||L2 =\", l2)\n",
    "    if (l2):\n",
    "        c = l1/l2\n",
    "    C1 = min(C1, c)\n",
    "    C2 = max(C2, c)\n",
    "print(f\"{C1 = }\\n{C2 = }\")\n",
    "\n",
    "'''\n",
    "C1 = 1.1026288780635476\n",
    "C2 = 2.235176645875752\n",
    "\n",
    "C1 = 1.1173408176507174\n",
    "C2 = 2.235903466061794\n",
    "\n",
    "C1 = 1.1136659273429736\n",
    "C2 = 2.2360269616766137\n",
    "\n",
    "C1 = 1.091236262999598\n",
    "C2 = 2.2356429121918144\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpR6GBRtKmXq"
   },
   "source": [
    "# Задача 3.  Евклидова и бесконечная норма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ7BfspuTsOt"
   },
   "source": [
    " Пусть x — вектор размерности m, а A — матрица m×n. Докажите следующие неравенства и приведите\n",
    "примеры таких x и A, при которых неравенства обращаются в равенства: \n",
    "\n",
    "- $\\|x\\|_2 \\leq \\sqrt{m}\\|x\\|_{\\infty}$\n",
    "- $\\|A\\|_{\\infty} \\leq \\sqrt{n}\\|A\\|_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Примеры векторов, у которых достигается равенство:\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Есть ли случаи, когда вторая норма больше? False\n",
      "Примеры матриц, у которых достигается равенство:\n",
      "[[-0.  0. -0.  0.  0.]\n",
      " [ 0. -0. -0.  0.  0.]\n",
      " [-0. -0. -0.  0. -0.]\n",
      " [-0.  0.  0. -0. -0.]\n",
      " [ 0. -0. -0. -0.  0.]\n",
      " [-0. -0. -0.  0. -0.]]\n",
      "Есть ли случаи, когда бесконечная норма больше? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import sqrt\n",
    "m = 6\n",
    "n = 5\n",
    "flag = False\n",
    "print(\"Примеры векторов, у которых достигается равенство:\")\n",
    "for i in range(1000):\n",
    "    x = np.random.random(m)*random.randrange(-100, 100)\n",
    "    l2 = np.linalg.norm(x, 2)\n",
    "    li = np.linalg.norm(x, np.inf)\n",
    "    flag = flag or (l2 - sqrt(m)*li > 0)\n",
    "    if (sqrt(m)*li - l2 < 0.0001):\n",
    "        print(x)\n",
    "print(\"Есть ли случаи, когда вторая норма больше?\", flag)\n",
    "\n",
    "flag = False\n",
    "print(\"Примеры матриц, у которых достигается равенство:\")\n",
    "for i in range(500):\n",
    "    A = np.random.randn(m, n) * random.randrange(-100, 100)\n",
    "    #print(A)\n",
    "    lm2 = np.linalg.norm(A, 2)\n",
    "    lmi = np.linalg.norm(A, np.inf)\n",
    "    #print(lm2, lmi)\n",
    "    flag = flag or (lmi - sqrt(n)*lm2 > 0)\n",
    "    if (sqrt(n)*lm2 - lmi < 0.01):\n",
    "        print(A)\n",
    "print(\"Есть ли случаи, когда бесконечная норма больше?\", flag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-476ZEtKmk5"
   },
   "source": [
    "# Задача 4. Норма Фробениуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzG3RPf-T07c"
   },
   "source": [
    "Докажите, что для любой унитарной матрицы U (и для произвольной матрицы A) имеет место равенство\n",
    "\n",
    " $∥UA∥_F = ∥AU∥_F = ∥A∥_F$ , \n",
    " \n",
    " где $∥ ∥_F$ — норма Фробениуса.\n",
    "\n",
    "Указание.  \n",
    "Задачу можно решить без вычислений, если использовать геометрический смысл нормы Фробениуса и геометрические свойства умножения на унитарную матрицу (что при умножении на неё сохраняется). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8jGlqhJKmpB"
   },
   "source": [
    "# Задача 5. Тензорная свёртка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smdRrcYuT4he"
   },
   "source": [
    "Рассмотрим функцию, отображающую шесть тензоров на один тензор: $Z\\left(\\lambda^{(1)}, \\lambda^{(2)}, \\lambda^{(3)}, \\Gamma^{(1)}, \\Gamma^{(2)}, U\\right)$ :\n",
    "\n",
    "\n",
    "$$\n",
    "Z_{a h i j}=\\sum_{b c d e f g} \\lambda^{(1)}{ }_{a b} \\Gamma_{c b d}^{(1)} \\lambda^{(2)}{ }_{d e} \\Gamma_{f e g}^{(2)} \\lambda_{g h}^{(3)} U_{i j c f}\n",
    "$$ \n",
    "\n",
    "редположив, что все индексы пробегают значения от 1 до χ, проведите эксперимент и сравните скорость\n",
    "различных реализаций функции Z. Исследуйте значения χ в диапазоне 3–50. \n",
    "\n",
    "\n",
    "- В файле convolution. ipynb вы можете найти релизацию глупого способа вычисления этой свертки, который требует $\\chi^4 \\times \\chi^6=\\chi^{10}$ операций. На самом деле это можно вычислить гораздо быстрее!\n",
    "- С помощью функции numpy . einsum (нужно использовать аргумент optimize), можно добиться намного большей производительности. Чтобы понять, что происходит под капотом, воспользуйтесь функцией numpy.einsum_path. Какое минимальное количество операций требуется для вычисления $Z$ ?\n",
    "- Посмотрев на вывод функции numpy.einsum_path, peализуйте алгоритм для вычисления $Z$, который столь же эффективен, как numpy.einsum, но использует более элементарные numpy.dot и numpy.tensor_dot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "634QUTkyKnWR"
   },
   "source": [
    "# Задача 6.  k-means clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gHzjikte83x"
   },
   "source": [
    "Выбор метрики (нормы разницы между любыми двумя векторами, или функции расстояния между любой парой точек) очень важен для многих алгоритмов машинного обучения. Рассмотрим на примере задачи кластеризации. \n",
    "\n",
    "Кластеризация — это разделение множества входных векторов на группы (кластеры) по степени «схожести» друг с другом.\n",
    "\n",
    "Кластеризация в Data Mining приобретает ценность тогда, когда она выступает одним из этапов анализа данных, построения законченного аналитического решения. Аналитику часто легче выделить группы схожих объектов, изучить их особенности и построить для каждой группы отдельную модель, чем создавать одну общую модель для всех данных. Таким приемом постоянно пользуются в маркетинге, выделяя группы клиентов, покупателей, товаров и разрабатывая для каждой из них отдельную стратегию.\n",
    "\n",
    "\n",
    "Евклидова метрика \n",
    "\n",
    "\n",
    "— наиболее распространенная. Она является геометрическим расстоянием в многомерном пространстве.\n",
    "\n",
    "\n",
    "Квадрат евклидовой метрики. \n",
    "\n",
    "\n",
    "Иногда может возникнуть желание возвести в квадрат стандартное евклидово расстояние, чтобы придать большие веса более отдаленным друг от друга объектам.\n",
    "\n",
    "\n",
    "Метрика городских кварталов (манхэттенская). \n",
    "\n",
    "\n",
    "Это расстояние является суммой модулей разностей координат. В большинстве случаев эта метрика приводит к таким же результатам, как и для обычного расстояния Евклида. Однако отметим, что для этой меры влияние отдельных больших разностей (выбросов) уменьшается (так как они не возводятся в квадрат).\n",
    "\n",
    "Расстояние Чебышева. \n",
    "\n",
    "Это метрика шахматной доски (Расстоянием Чебышёва между n-мерными числовыми векторами называется максимум модуля разности компонент этих векторов). Это расстояние может оказаться полезным, когда желают определить два объекта как «различные», если они различаются по какой-либо одной координате (каким-либо одним измерением).\n",
    "\n",
    "Расстояние Чебышёва называют также метрикой Чебышёва, равномерной метрикой, sup-метрикой и бокс-метрикой; также иногда она называется метрикой решётки, метрикой шахматной доски, метрикой хода короля и 8-метрикой.\n",
    "\n",
    "Степенная метрика. \n",
    "\n",
    "Иногда желают прогрессивно увеличить или уменьшить вес, относящийся к размерности, для которой соответствующие объекты сильно отличаются. Это может быть достигнуто с использованием степенного расстояния.\n",
    "\n",
    "\n",
    "Выбор метрики (критерия схожести) лежит полностью на исследователе. При выборе различных мер результаты кластеризации могут существенно отличаться.\n",
    "\n",
    "Алгоритм k-means (k-средних)\n",
    "\n",
    "Наиболее простой, но в то же время достаточно неточный метод кластеризации в классической реализации. Он разбивает множество элементов векторного пространства на заранее известное число кластеров k. Действие алгоритма таково, что он стремится минимизировать среднеквадратичное отклонение на точках каждого кластера. Основная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Алгоритм завершается, когда на какой-то итерации не происходит изменения кластеров.\n",
    "\n",
    "Проблемы алгоритма k-means:\n",
    "* необходимо заранее знать количество кластеров. Мной было предложено метод определения количества кластеров, который основывался на нахождении кластеров, распределенных по некоему закону (в моем случае все сводилось к нормальному закону). После этого выполнялся классический алгоритм k-means, который давал более точные результаты.\n",
    "* алгоритм очень чувствителен к выбору начальных центров кластеров. Классический вариант подразумевает случайный выбор класторов, что очень часто являлось источником погрешности. Как вариант решения, необходимо проводить исследования объекта для более точного определения центров начальных кластеров. В моем случае на начальном этапе предлагается принимать в качестве центов самые отдаленные точки кластеров.\n",
    "* не справляется с задачей, когда объект принадлежит к разным кластерам в равной степени или не принадлежит ни одному.\n",
    "\n",
    "\n",
    "В блокноте kmeans.ipynb вы можете найти наивную реализацию.\n",
    "Изучите код, убедитесь, что вы его поняли. Вы найдете там две функции dist_i и dist_ij, которые\n",
    "(намеренно) реализованы довольно неэффективно. Улучшите их, избавившись от циклов с помощью век-\n",
    "торизации из numpy, и измерьте ускорение алгоритма в целом при N = 10000.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKnAIng1T-Ex"
   },
   "source": [
    "# Дополнительное задание. Нечеткий алгоритм кластеризации с-means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umU-jwFAT7nj"
   },
   "source": [
    "С последней проблемой k-means успешно справляется алгоритм с-means. Вместо однозначного ответа на вопрос к какому кластеру относится объект, он определяет вероятность того, что объект принадлежит к тому или иному кластеру. Таким образом, утверждение «объект А принадлежит к кластеру 1 с вероятностью 90%, к кластеру 2 — 10% » верно и более удобно.\n",
    "\n",
    "Остальные проблемы у с-means такие же, как у k-means, но они нивелируются благодаря нечеткости разбиения.\n",
    "\n",
    "Метод нечеткой кластеризации C-средних имеет ограниченное применение из-за существенного недостатка — невозможность корректного разбиения на кластеры, в случае когда кластеры имеют различную дисперсию по различным размерностям (осям) элементов (например, кластер имеет форму эллипса). Данный недостаток устранен в алгоритмах Mixture models и GMM (Gaussian mixture models). \n",
    "\n",
    "\n",
    "Документация методов кластеризации для sklearn есть здесь https://scikit-learn.org/stable/modules/clustering.html#k-means . \n",
    "\n",
    "\n",
    "\n",
    "Используя библиотеку scikit-learn, реализуйте Gaussian mixture models и обычный k-means.  Подберите такой набор данных, на котором первый метод справляется хорошо, а второй метод даёт плохие результаты, и продемонстрируйте это. Сделайте это для нескольких разных метрик и сравните результаты между собой.\n",
    "\n",
    "https://scikit-learn.ru/example/  примеры подобного.\n",
    "\n",
    "https://neurohive.io/ru/osnovy-data-science/vvedenie-v-scikit-learn/  введение в sklearn. На этом сайте много полезных статей и ссылок на курсы. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MeXTSdSfKdL2",
    "sS3EHa1aKmJi",
    "gpR6GBRtKmXq",
    "8-476ZEtKmk5",
    "s8jGlqhJKmpB",
    "634QUTkyKnWR",
    "gKnAIng1T-Ex"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
